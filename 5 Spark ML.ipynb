{"cells":[{"cell_type":"code","source":["#Feature Extraction - TF IDF\nfrom pyspark.ml.feature import HashingTF, IDF, Tokenizer\n\nsentenceData = spark.createDataFrame([\n    (0.0, \"Hi I heard about Spark\"),\n    (0.0, \"I wish Java could use case classes\"),\n    (1.0, \"Logistic regression models are neat\")\n], [\"label\", \"sentence\"])\n\ntokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\nwordsData = tokenizer.transform(sentenceData)\n\n\nhashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\nfeaturizedData = hashingTF.transform(wordsData)\n\n# alternatively, CountVectorizer can also be used to get term frequency vectors\n\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\nidfModel = idf.fit(featurizedData)\nrescaledData = idfModel.transform(featurizedData)\n\nrescaledData.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68a7b267-2a1f-4a62-b6fd-d6cbab3efd00"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"sentenceData","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"wordsData","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"},{"metadata":{},"name":"words","nullable":true,"type":{"containsNull":true,"elementType":"string","type":"array"}}],"type":"struct"},"tableIdentifier":null},{"name":"featurizedData","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"},{"metadata":{},"name":"words","nullable":true,"type":{"containsNull":true,"elementType":"string","type":"array"}},{"metadata":{"ml_attr":{"num_attrs":20}},"name":"rawFeatures","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null},{"name":"rescaledData","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"},{"metadata":{},"name":"words","nullable":true,"type":{"containsNull":true,"elementType":"string","type":"array"}},{"metadata":{"ml_attr":{"num_attrs":20}},"name":"rawFeatures","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}},{"metadata":{},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+-----+--------------------+--------------------+--------------------+--------------------+\n|label|            sentence|               words|         rawFeatures|            features|\n+-----+--------------------+--------------------+--------------------+--------------------+\n|  0.0|Hi I heard about ...|[hi, i, heard, ab...|(20,[0,5,9,17],[1...|(20,[0,5,9,17],[0...|\n|  0.0|I wish Java could...|[i, wish, java, c...|(20,[2,7,9,13,15]...|(20,[2,7,9,13,15]...|\n|  1.0|Logistic regressi...|[logistic, regres...|(20,[4,6,13,15,18...|(20,[4,6,13,15,18...|\n+-----+--------------------+--------------------+--------------------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+--------------------+--------------------+--------------------+\nlabel|            sentence|               words|         rawFeatures|            features|\n+-----+--------------------+--------------------+--------------------+--------------------+\n  0.0|Hi I heard about ...|[hi, i, heard, ab...|(20,[0,5,9,17],[1...|(20,[0,5,9,17],[0...|\n  0.0|I wish Java could...|[i, wish, java, c...|(20,[2,7,9,13,15]...|(20,[2,7,9,13,15]...|\n  1.0|Logistic regressi...|[logistic, regres...|(20,[4,6,13,15,18...|(20,[4,6,13,15,18...|\n+-----+--------------------+--------------------+--------------------+--------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Feature Transformation  - Tokenizer\n\nfrom pyspark.ml.feature import Tokenizer, RegexTokenizer\nfrom pyspark.sql.functions import col, udf\nfrom pyspark.sql.types import IntegerType\n\nsentenceDataFrame = spark.createDataFrame([\n    (0, \"Hi I heard about Spark\"),\n    (1, \"I wish Java could use case classes\"),\n    (2, \"Logistic,regression,models,are,neat\")\n], [\"id\", \"sentence\"])\n\ntokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n\nregexTokenizer = RegexTokenizer(inputCol=\"sentence\", outputCol=\"words\", pattern=\"\\\\W\")\n# alternatively, pattern=\"\\\\w+\", gaps(False)\n\ncountTokens = udf(lambda words: len(words), IntegerType())\n\ntokenized = tokenizer.transform(sentenceDataFrame)\ntokenized.select(\"sentence\", \"words\")\\\n    .withColumn(\"tokens\", countTokens(col(\"words\"))).show(truncate=False)\n\nregexTokenized = regexTokenizer.transform(sentenceDataFrame)\nregexTokenized.select(\"sentence\", \"words\") \\\n    .withColumn(\"tokens\", countTokens(col(\"words\"))).show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"12f89ba6-a771-4fd4-b233-560d3ae31cc9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"sentenceDataFrame","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"id","nullable":true,"type":"long"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"tokenized","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"id","nullable":true,"type":"long"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"},{"metadata":{},"name":"words","nullable":true,"type":{"containsNull":true,"elementType":"string","type":"array"}}],"type":"struct"},"tableIdentifier":null},{"name":"regexTokenized","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"id","nullable":true,"type":"long"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"},{"metadata":{},"name":"words","nullable":true,"type":{"containsNull":true,"elementType":"string","type":"array"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+-----------------------------------+------------------------------------------+------+\n|sentence                           |words                                     |tokens|\n+-----------------------------------+------------------------------------------+------+\n|Hi I heard about Spark             |[hi, i, heard, about, spark]              |5     |\n|I wish Java could use case classes |[i, wish, java, could, use, case, classes]|7     |\n|Logistic,regression,models,are,neat|[logistic,regression,models,are,neat]     |1     |\n+-----------------------------------+------------------------------------------+------+\n\n+-----------------------------------+------------------------------------------+------+\n|sentence                           |words                                     |tokens|\n+-----------------------------------+------------------------------------------+------+\n|Hi I heard about Spark             |[hi, i, heard, about, spark]              |5     |\n|I wish Java could use case classes |[i, wish, java, could, use, case, classes]|7     |\n|Logistic,regression,models,are,neat|[logistic, regression, models, are, neat] |5     |\n+-----------------------------------+------------------------------------------+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------+------------------------------------------+------+\nsentence                           |words                                     |tokens|\n+-----------------------------------+------------------------------------------+------+\nHi I heard about Spark             |[hi, i, heard, about, spark]              |5     |\nI wish Java could use case classes |[i, wish, java, could, use, case, classes]|7     |\nLogistic,regression,models,are,neat|[logistic,regression,models,are,neat]     |1     |\n+-----------------------------------+------------------------------------------+------+\n\n+-----------------------------------+------------------------------------------+------+\nsentence                           |words                                     |tokens|\n+-----------------------------------+------------------------------------------+------+\nHi I heard about Spark             |[hi, i, heard, about, spark]              |5     |\nI wish Java could use case classes |[i, wish, java, could, use, case, classes]|7     |\nLogistic,regression,models,are,neat|[logistic, regression, models, are, neat] |5     |\n+-----------------------------------+------------------------------------------+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Feature Selector - Vector Slicer\n\nfrom pyspark.ml.feature import VectorSlicer\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.sql.types import Row\n\ndf = spark.createDataFrame([\n    Row(userFeatures=Vectors.sparse(3, {0: -2.0, 1: 2.3})),\n    Row(userFeatures=Vectors.dense([-2.0, 2.3, 0.0]))])\n\nslicer = VectorSlicer(inputCol=\"userFeatures\", outputCol=\"features\", indices=[1])\n\noutput = slicer.transform(df)\n\noutput.select(\"userFeatures\", \"features\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"149ec783-4bea-4fff-b3c2-b16598cc2dc7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"userFeatures","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null},{"name":"output","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"userFeatures","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}},{"metadata":{"ml_attr":{"num_attrs":1}},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+--------------------+-------------+\n|        userFeatures|     features|\n+--------------------+-------------+\n|(3,[0,1],[-2.0,2.3])|(1,[0],[2.3])|\n|      [-2.0,2.3,0.0]|        [2.3]|\n+--------------------+-------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-------------+\n        userFeatures|     features|\n+--------------------+-------------+\n(3,[0,1],[-2.0,2.3])|(1,[0],[2.3])|\n      [-2.0,2.3,0.0]|        [2.3]|\n+--------------------+-------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Corelation\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.stat import Correlation\n\ndata = [(Vectors.sparse(4, [(0, 1.0), (3, -2.0)]),),\n        (Vectors.dense([4.0, 5.0, 0.0, 3.0]),),\n        (Vectors.dense([6.0, 7.0, 0.0, 8.0]),),\n        (Vectors.sparse(4, [(0, 9.0), (3, 1.0)]),)]\ndf = spark.createDataFrame(data, [\"features\"])\ndf.show()\n\n\nr1 = Correlation.corr(df, \"features\").head()\nprint(\"Pearson correlation matrix:\\n\" + str(r1[0]))\n\nr2 = Correlation.corr(df, \"features\", \"spearman\").head()\nprint(\"Spearman correlation matrix:\\n\" + str(r2[0]))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3da859aa-6606-4e2c-9ff3-9deb10155502"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+--------------------+\n|            features|\n+--------------------+\n|(4,[0,3],[1.0,-2.0])|\n|   [4.0,5.0,0.0,3.0]|\n|   [6.0,7.0,0.0,8.0]|\n| (4,[0,3],[9.0,1.0])|\n+--------------------+\n\nPearson correlation matrix:\nDenseMatrix([[1.        , 0.05564149,        nan, 0.40047142],\n             [0.05564149, 1.        ,        nan, 0.91359586],\n             [       nan,        nan, 1.        ,        nan],\n             [0.40047142, 0.91359586,        nan, 1.        ]])\nSpearman correlation matrix:\nDenseMatrix([[1.        , 0.10540926,        nan, 0.4       ],\n             [0.10540926, 1.        ,        nan, 0.9486833 ],\n             [       nan,        nan, 1.        ,        nan],\n             [0.4       , 0.9486833 ,        nan, 1.        ]])\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+\n            features|\n+--------------------+\n(4,[0,3],[1.0,-2.0])|\n   [4.0,5.0,0.0,3.0]|\n   [6.0,7.0,0.0,8.0]|\n (4,[0,3],[9.0,1.0])|\n+--------------------+\n\nPearson correlation matrix:\nDenseMatrix([[1.        , 0.05564149,        nan, 0.40047142],\n             [0.05564149, 1.        ,        nan, 0.91359586],\n             [       nan,        nan, 1.        ,        nan],\n             [0.40047142, 0.91359586,        nan, 1.        ]])\nSpearman correlation matrix:\nDenseMatrix([[1.        , 0.10540926,        nan, 0.4       ],\n             [0.10540926, 1.        ,        nan, 0.9486833 ],\n             [       nan,        nan, 1.        ,        nan],\n             [0.4       , 0.9486833 ,        nan, 1.        ]])\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Linear Regression\n\nfrom pyspark.ml.regression import LinearRegression\n\n# Load training data\ntraining = spark.read.format(\"libsvm\")\\\n    .load(\"/FileStore/tables/data_mllib_sample_linear_regression_data.txt\")\n\nlr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n\n# Fit the model\nlrModel = lr.fit(training)\n\n# Print the coefficients and intercept for linear regression\nprint(\"Coefficients: %s\" % str(lrModel.coefficients))\nprint(\"Intercept: %s\" % str(lrModel.intercept))\n\n# Summarize the model over the training set and print out some metrics\ntrainingSummary = lrModel.summary\nprint(\"numIterations: %d\" % trainingSummary.totalIterations)\nprint(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\ntrainingSummary.residuals.show()\nprint(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\nprint(\"r2: %f\" % trainingSummary.r2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d12b17e6-a413-4c33-baa3-9c6f2fe21fe3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"training","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{"numFeatures":10},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">Coefficients: [0.0,0.32292516677405936,-0.3438548034562218,1.9156017023458414,0.05288058680386263,0.765962720459771,0.0,-0.15105392669186682,-0.21587930360904642,0.22025369188813426]\nIntercept: 0.1598936844239736\nnumIterations: 7\nobjectiveHistory: [0.49999999999999994, 0.4967620357443381, 0.4936361664340463, 0.4936351537897608, 0.4936351214177871, 0.49363512062528014, 0.4936351206216114]\n+--------------------+\n|           residuals|\n+--------------------+\n|  -9.889232683103197|\n|  0.5533794340053554|\n|  -5.204019455758823|\n| -20.566686715507508|\n|    -9.4497405180564|\n|  -6.909112502719486|\n|  -10.00431602969873|\n|   2.062397807050484|\n|  3.1117508432954772|\n| -15.893608229419382|\n|  -5.036284254673026|\n|   6.483215876994333|\n|  12.429497299109002|\n|  -20.32003219007654|\n| -2.0049838218725005|\n| -17.867901734183793|\n|   7.646455887420495|\n| -2.2653482182417406|\n|-0.10308920436195645|\n|  -1.380034070385301|\n+--------------------+\nonly showing top 20 rows\n\nRMSE: 10.189077\nr2: 0.022861\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Coefficients: [0.0,0.32292516677405936,-0.3438548034562218,1.9156017023458414,0.05288058680386263,0.765962720459771,0.0,-0.15105392669186682,-0.21587930360904642,0.22025369188813426]\nIntercept: 0.1598936844239736\nnumIterations: 7\nobjectiveHistory: [0.49999999999999994, 0.4967620357443381, 0.4936361664340463, 0.4936351537897608, 0.4936351214177871, 0.49363512062528014, 0.4936351206216114]\n+--------------------+\n           residuals|\n+--------------------+\n  -9.889232683103197|\n  0.5533794340053554|\n  -5.204019455758823|\n -20.566686715507508|\n    -9.4497405180564|\n  -6.909112502719486|\n  -10.00431602969873|\n   2.062397807050484|\n  3.1117508432954772|\n -15.893608229419382|\n  -5.036284254673026|\n   6.483215876994333|\n  12.429497299109002|\n  -20.32003219007654|\n -2.0049838218725005|\n -17.867901734183793|\n   7.646455887420495|\n -2.2653482182417406|\n-0.10308920436195645|\n  -1.380034070385301|\n+--------------------+\nonly showing top 20 rows\n\nRMSE: 10.189077\nr2: 0.022861\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d56ca426-f6bc-4e19-b13a-8d80064b839c"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"5 Spark ML","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4462370009969870}},"nbformat":4,"nbformat_minor":0}
