{"cells":[{"cell_type":"markdown","source":["## Training XGBoost4J-Spark with PySpark\n\n#### Introduction to XGBoost\n\nXGBoost stands for “eXtreme Gradient Boosting” and is an open-source machine learning library that implements optimized distributed gradient boosting algorithms. It has become one of the most popular ML libraries because of its fast performance and high scalability. One of its important features is its portability- being able to use the same code on many distributed environments such as Kubernetes, Hadoop, Dask, or MPI. However, deploying distributed XGBoost on Spark can be more complicated as it requires using the XGBoost4J-Spark package, which can be difficult to integrate with Python and MLflow. To showcase how to solve these issues, this notebook will begin with an overview of single-node XGBoost and MLflow, how to build with XGBoost4J-Spark and integrate it with MLflow, and how to create a PySpark wrapper around XGBoost4J-Spark.\n\n#### How does XGBoost work?\n\nGradient boosted trees are a supervised learning algorithm, which use the predictions of a collection of simple tree models for classification or regression. XGBoost uses a regularized loss function (the difference between the labels and the predictions) and another cost function for model complexity. These loss terms are minimized using gradient descent to reduce error and complexity of the model to move towards the simplest and most accurate model. This is a very broad generalization of the algorithm. For more detail, check out the XGBoost documentation on its powerful algorithm. (https://xgboost.readthedocs.io/en/latest/tutorials/model.html)\n\n#### MLflow\n\n<img src=\"https://databricks.com/wp-content/uploads/2020/04/databricks-adds-access-control-to-mlflow-model-registry_01.jpg\" alt=\"drawing\" width=\"700\"/>\n\nMLflow is a “platform for managing the end-to-end machine learning lifecycle.” It allows you to track experiments, deploy models to model serving tools, register models to manage them from staging to production, and package them to ease collaboration. The platform supports multiple languages, such as Python, Java, and R. It is a key component of the Databricks platform, which combines the multi-language support of both platforms and high-collaboration capabilities for fast development and clear understanding of the ML lifecycle on Spark."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d07b6ba-c6d1-4cc1-b479-f53db7d1f4c4"}}},{"cell_type":"markdown","source":["#### XGBoost Example\n\nThe following example shows how the non-Spark XGBoost Python API can be used to train on the iris dataset. It is illustrative of how to integrate Spark data ingestion and MLflow with XGBoost with a non-distributed training model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82301a97-4060-49b6-95f7-e64624938a11"}}},{"cell_type":"code","source":["%python\nfrom pyspark.sql.types import LongType\nfrom pyspark.sql.functions import *\n\nfrom sklearn.metrics import precision_score\nfrom sklearn.model_selection import train_test_split\n\nimport xgboost as xgb\nimport mlflow.xgboost\n\n# Read iris dataset\ndata = (spark\n        .read\n        .format('csv')\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .load('/databricks-datasets/Rdatasets/data-001/csv/datasets/iris.csv')\n       )\n\n\n# UDF for converting labels to indexes\ndef cnvt_species(s):\n    species = ['setosa', 'versicolor', 'virginica']\n    return species.index(s)\ncnvt_species_udf = udf(cnvt_species, LongType())\n\n# Select, rename columns, apply UDF on label column\ndata = (data.select(col(\"`Sepal.Length`\").alias('sepal_length'), \n                col(\"`Sepal.Width`\").alias('sepal_width'), \n                col(\"`Petal.Length`\").alias('petal_length'), \n                col(\"`Petal.Width`\").alias('petal_width'), \n                cnvt_species_udf(col(\"Species\")).alias(\"species\")))\n\n# Split to train/test dataset\ntraining_data, testing_data = train_test_split(data.toPandas())\n\n# Load training data into a DMatrix\nxgtrain = xgb.DMatrix(training_data[[\"sepal_length\",\"sepal_width\", \"petal_length\", \"petal_width\"]].values, training_data['species'])\n\n# Start MLflow training run\nwith mlflow.start_run():\n  \n  # Auto-log the model parameters with mlflow.xgboost.autolog\n  mlflow.xgboost.autolog()\n  param = {'max_depth': 2, \n           'objective': 'multi:softmax', \n           'num_class':3, \n           'nthread':8}\n  bst = xgb.train(param, xgtrain, 10)\n\n  # Load testing data into DMatrix\n  dtest = xgb.DMatrix(testing_data[[\"sepal_length\",\"sepal_width\", \n                                    \"petal_length\", \"petal_width\"]].values)\n  # Predict testing data\n  ypred = bst.predict(dtest)\n\n  # Calculate accuracy score\n  p_score = precision_score(testing_data[\"species\"],ypred, average='micro')\n\n  # Log precision score as a metric\n  mlflow.log_metric(\"precision_score\", p_score)\n  print(\"XGBoost Model Precision Score:\",p_score)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"79cb4226-6319-4d04-9343-8bff1c9f3009"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"data","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"sepal_length","nullable":true,"type":"double"},{"metadata":{},"name":"sepal_width","nullable":true,"type":"double"},{"metadata":{},"name":"petal_length","nullable":true,"type":"double"},{"metadata":{},"name":"petal_width","nullable":true,"type":"double"},{"metadata":{},"name":"species","nullable":true,"type":"long"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/mlflow/xgboost.py:333: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n  all_arg_names = inspect.getargspec(original)[0]  # pylint: disable=W1505\nXGBoost Model Precision Score: 1.0\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/mlflow/xgboost.py:333: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n  all_arg_names = inspect.getargspec(original)[0]  # pylint: disable=W1505\nXGBoost Model Precision Score: 1.0\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### XGBoost4J-Spark Example\n\nXGBoost4J-Spark does not have an official Python API, so this example is in Scala to show how to train a distributed model without requiring a Python wrapper. This would be useful for a Scala or a multi-language ML pipeline."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d79becdb-3f7b-4442-bbc9-e6eaa29de18f"}}},{"cell_type":"code","source":["%sql\nCREATE TABLE IF NOT EXISTS iris (rowNum int, SepalLength double, SepalWidth double, PetalLength double, PetalWidth double, Species string)\nUSING com.databricks.spark.csv\nOPTIONS (path \"/databricks-datasets/Rdatasets/data-001/csv/datasets/iris.csv\", header \"true\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa04e473-4874-4ed0-ac92-32ff5fd9907c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.ml.tuning._\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.types._\n\nimport org.mlflow.tracking.ActiveRun\nimport org.mlflow.tracking.MlflowContext\nimport org.mlflow.tracking.MlflowClient\nimport java.io.{File,PrintWriter}\n\nimport ml.dmlc.xgboost4j.scala.spark.{XGBoostClassifier, XGBoostClassificationModel}\n\n// Set user value to your username\nval user = \"stephen.offer@databricks.com\"\n\n// Read dataset\nval rawInput = spark.sql(\"select * from iris\")\n\n// Split the data into training and test set\nval Array(training, test) = rawInput.randomSplit(Array(0.8, 0.2), 123)\n\n// Create Vector Assembler stage\nval assembler = new VectorAssembler()\n  .setInputCols(Array(\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"))\n  .setOutputCol(\"features\")\n\n// Create String to Index stage\nval labelIndexer = new StringIndexer()\n  .setInputCol(\"Species\")\n  .setOutputCol(\"classIndex\")\n  .fit(training)\n\n// Create XGBoostClassifier model\nval booster = new XGBoostClassifier(\n  Map(\"eta\" -> 0.1f,\n    \"max_depth\" -> 2,\n    \"objective\" -> \"multi:softprob\",\n    \"num_class\" -> 3,\n    \"num_round\" -> 100,\n    \"num_workers\" -> 2,\n    \"tree_method\" -> \"auto\"\n  )\n)\nbooster.setFeaturesCol(\"features\")\nbooster.setLabelCol(\"classIndex\")\n\n// Create the training pipeline\nval pipeline = new Pipeline()\n  .setStages(Array(assembler, labelIndexer, booster))\n\n// Start MLflow context\nval mlflowContext = new MlflowContext()\nval experimentName = \"/Users/stephen.offer@databricks.com/xgboost4j-spark-quickstart\"\nval client = mlflowContext.getClient()\nval experimentOpt = client.getExperimentByName(experimentName);\n\nif (!experimentOpt.isPresent()) {\n  client.createExperiment(experimentName)\n}\nmlflowContext.setExperimentName(experimentName)\nval run = mlflowContext.startRun(\"run\")\n\n// Train model\nval model = pipeline.fit(training)\n\n// Batch prediction\nval prediction = model.transform(test)\nprediction.show(true)\n\n// Model evaluation\nval evaluator = new MulticlassClassificationEvaluator()\nevaluator.setLabelCol(\"classIndex\")\nevaluator.setPredictionCol(\"prediction\")\n\n// Calculate the accuracy of the model\nval accuracy = evaluator.evaluate(prediction)\nprintln(\"The model accuracy is : \" + accuracy)\n\n// Save the model and log the path as a parameter\nval scratchDir = s\"dbfs:/tmp/stephen.offer@databricks.com/xgboost-model\"\nmodel.write.overwrite().save(scratchDir)\nrun.logParam(scratchDir, \"model_path\")\n\n// Log the accuracy as a metric\nrun.logMetric(\"accuracy\", accuracy)\nrun.endRun()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"044a2615-2253-4fc0-b83c-d49c7a9bf8f4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"rawInput","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"rowNum","type":"integer","nullable":true,"metadata":{}},{"name":"SepalLength","type":"double","nullable":true,"metadata":{}},{"name":"SepalWidth","type":"double","nullable":true,"metadata":{}},{"name":"PetalLength","type":"double","nullable":true,"metadata":{}},{"name":"PetalWidth","type":"double","nullable":true,"metadata":{}},{"name":"Species","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null},{"name":"training","typeStr":"org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]","schema":{"type":"struct","fields":[{"name":"rowNum","type":"integer","nullable":true,"metadata":{}},{"name":"SepalLength","type":"double","nullable":true,"metadata":{}},{"name":"SepalWidth","type":"double","nullable":true,"metadata":{}},{"name":"PetalLength","type":"double","nullable":true,"metadata":{}},{"name":"PetalWidth","type":"double","nullable":true,"metadata":{}},{"name":"Species","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null},{"name":"test","typeStr":"org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]","schema":{"type":"struct","fields":[{"name":"rowNum","type":"integer","nullable":true,"metadata":{}},{"name":"SepalLength","type":"double","nullable":true,"metadata":{}},{"name":"SepalWidth","type":"double","nullable":true,"metadata":{}},{"name":"PetalLength","type":"double","nullable":true,"metadata":{}},{"name":"PetalWidth","type":"double","nullable":true,"metadata":{}},{"name":"Species","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null},{"name":"prediction","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"rowNum","type":"integer","nullable":true,"metadata":{}},{"name":"SepalLength","type":"double","nullable":true,"metadata":{}},{"name":"SepalWidth","type":"double","nullable":true,"metadata":{}},{"name":"PetalLength","type":"double","nullable":true,"metadata":{}},{"name":"PetalWidth","type":"double","nullable":true,"metadata":{}},{"name":"Species","type":"string","nullable":true,"metadata":{}},{"name":"features","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{"ml_attr":{"attrs":{"numeric":[{"idx":0,"name":"SepalLength"},{"idx":1,"name":"SepalWidth"},{"idx":2,"name":"PetalLength"},{"idx":3,"name":"PetalWidth"}]},"num_attrs":4}}},{"name":"classIndex","type":"double","nullable":false,"metadata":{"ml_attr":{"vals":["versicolor","virginica","setosa"],"type":"nominal","name":"classIndex"}}},{"name":"rawPrediction","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}},{"name":"probability","type":{"type":"udt","class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"type":"struct","fields":[{"name":"type","type":"byte","nullable":false,"metadata":{}},{"name":"size","type":"integer","nullable":true,"metadata":{}},{"name":"indices","type":{"type":"array","elementType":"integer","containsNull":false},"nullable":true,"metadata":{}},{"name":"values","type":{"type":"array","elementType":"double","containsNull":false},"nullable":true,"metadata":{}}]}},"nullable":true,"metadata":{}},{"name":"prediction","type":"double","nullable":false,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.0.235.133, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=2}\n+------+-----------+----------+-----------+----------+----------+-----------------+----------+--------------------+--------------------+----------+\n|rowNum|SepalLength|SepalWidth|PetalLength|PetalWidth|   Species|         features|classIndex|       rawPrediction|         probability|prediction|\n+------+-----------+----------+-----------+----------+----------+-----------------+----------+--------------------+--------------------+----------+\n|     3|        4.7|       3.2|        1.3|       0.2|    setosa|[4.7,3.2,1.3,0.2]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n|     7|        4.6|       3.4|        1.4|       0.3|    setosa|[4.6,3.4,1.4,0.3]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n|    13|        4.8|       3.0|        1.4|       0.1|    setosa|[4.8,3.0,1.4,0.1]|       2.0|[-1.4854443073272...|[0.00769940251484...|       2.0|\n|    14|        4.3|       3.0|        1.1|       0.1|    setosa|[4.3,3.0,1.1,0.1]|       2.0|[-1.4854443073272...|[0.00769940251484...|       2.0|\n|    19|        5.7|       3.8|        1.7|       0.3|    setosa|[5.7,3.8,1.7,0.3]|       2.0|[-0.6133861541748...|[0.01823210716247...|       2.0|\n|    24|        5.1|       3.3|        1.7|       0.5|    setosa|[5.1,3.3,1.7,0.5]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n|    30|        4.7|       3.2|        1.6|       0.2|    setosa|[4.7,3.2,1.6,0.2]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n|    31|        4.8|       3.1|        1.6|       0.2|    setosa|[4.8,3.1,1.6,0.2]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n|    34|        5.5|       4.2|        1.4|       0.2|    setosa|[5.5,4.2,1.4,0.2]|       2.0|[-0.8276672363281...|[0.01476745773106...|       2.0|\n|    35|        4.9|       3.1|        1.5|       0.2|    setosa|[4.9,3.1,1.5,0.2]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n|    36|        5.0|       3.2|        1.2|       0.2|    setosa|[5.0,3.2,1.2,0.2]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n|    39|        4.4|       3.0|        1.3|       0.2|    setosa|[4.4,3.0,1.3,0.2]|       2.0|[-1.4854443073272...|[0.00769940251484...|       2.0|\n|    41|        5.0|       3.5|        1.3|       0.3|    setosa|[5.0,3.5,1.3,0.3]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n|    48|        4.6|       3.2|        1.4|       0.2|    setosa|[4.6,3.2,1.4,0.2]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n|    56|        5.7|       2.8|        4.5|       1.3|versicolor|[5.7,2.8,4.5,1.3]|       0.0|[3.24288702011108...|[0.99279528856277...|       0.0|\n|    62|        5.9|       3.0|        4.2|       1.5|versicolor|[5.9,3.0,4.2,1.5]|       0.0|[3.24288702011108...|[0.99249744415283...|       0.0|\n|    78|        6.7|       3.0|        5.0|       1.7|versicolor|[6.7,3.0,5.0,1.7]|       0.0|[-2.1966855525970...|[0.00137436285149...|       1.0|\n|    81|        5.5|       2.4|        3.8|       1.1|versicolor|[5.5,2.4,3.8,1.1]|       0.0|[3.11532020568847...|[0.98833745718002...|       0.0|\n|    86|        6.0|       3.4|        4.5|       1.6|versicolor|[6.0,3.4,4.5,1.6]|       0.0|[3.24288702011108...|[0.99256646633148...|       0.0|\n|    96|        5.7|       3.0|        4.2|       1.2|versicolor|[5.7,3.0,4.2,1.2]|       0.0|[3.24288702011108...|[0.99289292097091...|       0.0|\n+------+-----------+----------+-----------+----------+----------+-----------------+----------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\nThe model accuracy is : 0.9648572842765221\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.ml.tuning._\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.types._\nimport org.mlflow.tracking.ActiveRun\nimport org.mlflow.tracking.MlflowContext\nimport org.mlflow.tracking.MlflowClient\nimport java.io.{File, PrintWriter}\nimport ml.dmlc.xgboost4j.scala.spark.{XGBoostClassifier, XGBoostClassificationModel}\nuser: String = stephen.offer@databricks.com\nrawInput: org.apache.spark.sql.DataFrame = [rowNum: int, SepalLength: double ... 4 more fields]\ntraining: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [rowNum: int, SepalLength: double ... 4 more fields]\ntest: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [rowNum: int, SepalLength: double ... 4 more fields]\nassembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_96bbae204da6, handleInvalid=error, numInputCols=4\nlabelIndexer: org.apache.spark.ml.feature.StringIndexerModel = StringIndexerModel: uid=strIdx_8df10df736fa, handleInvalid=error\nbooster: ml.dmlc.xgboost4j.scala.spark.XGBoostClassifier = xgbc_d8d72f78e3f7\npipeline: org.apache.spark.ml.Pipeline = pipeline_b38c61b1669c\nmlflowContext: org.mlflow.tracking.MlflowContext = org.mlflow.tracking.MlflowContext@7c2b7f58\nexperimentName: String = /Users/stephen.offer@databricks.com/xgboost4j-spark-quickstart\nclient: org.mlflow.tracking.MlflowClient = org.mlflow.tracking.MlflowClient@24feb978\nexperimentOpt: java.util.Optional[org.mlflow.api.proto.Service.Experiment] =\nOptional[experiment_id: &quot;7845269&quot;\nname: &quot;/Users/stephen.offer@databricks.com/xgboost4j-spark-quickstart&quot;\nartifact_location: &quot;dbfs:/databricks/mlflow/7845269&quot;\nlifecycle_stage: &quot;active&quot;\nlast_update_time: 1597179788753\ncreation_time: 1597179788753\n]\nrun: org.mlflow.tracking.ActiveRun = org.mlflow.tracking.ActiveRun@68d65259\nmodel: org.apache.spark.ml.PipelineModel = pipeline_b38c61b1669c\nprediction: org.apache.spark.sql.DataFrame = [rowNum: int, SepalLength: double ... 9 more fields]\nevaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = MulticlassClassificationEvaluator: uid=mcEval_729d66c26560, metricName=f1, metricLabel=0.0, beta=1.0, eps=1.0E-15\naccuracy: Double = 0.9648572842765221\nscratchDir: String = dbfs:/tmp/stephen.offer@databricks.com/xgboost-model\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=10.0.235.133, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=2}\n+------+-----------+----------+-----------+----------+----------+-----------------+----------+--------------------+--------------------+----------+\nrowNum|SepalLength|SepalWidth|PetalLength|PetalWidth|   Species|         features|classIndex|       rawPrediction|         probability|prediction|\n+------+-----------+----------+-----------+----------+----------+-----------------+----------+--------------------+--------------------+----------+\n     3|        4.7|       3.2|        1.3|       0.2|    setosa|[4.7,3.2,1.3,0.2]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n     7|        4.6|       3.4|        1.4|       0.3|    setosa|[4.6,3.4,1.4,0.3]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n    13|        4.8|       3.0|        1.4|       0.1|    setosa|[4.8,3.0,1.4,0.1]|       2.0|[-1.4854443073272...|[0.00769940251484...|       2.0|\n    14|        4.3|       3.0|        1.1|       0.1|    setosa|[4.3,3.0,1.1,0.1]|       2.0|[-1.4854443073272...|[0.00769940251484...|       2.0|\n    19|        5.7|       3.8|        1.7|       0.3|    setosa|[5.7,3.8,1.7,0.3]|       2.0|[-0.6133861541748...|[0.01823210716247...|       2.0|\n    24|        5.1|       3.3|        1.7|       0.5|    setosa|[5.1,3.3,1.7,0.5]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n    30|        4.7|       3.2|        1.6|       0.2|    setosa|[4.7,3.2,1.6,0.2]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n    31|        4.8|       3.1|        1.6|       0.2|    setosa|[4.8,3.1,1.6,0.2]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n    34|        5.5|       4.2|        1.4|       0.2|    setosa|[5.5,4.2,1.4,0.2]|       2.0|[-0.8276672363281...|[0.01476745773106...|       2.0|\n    35|        4.9|       3.1|        1.5|       0.2|    setosa|[4.9,3.1,1.5,0.2]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n    36|        5.0|       3.2|        1.2|       0.2|    setosa|[5.0,3.2,1.2,0.2]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n    39|        4.4|       3.0|        1.3|       0.2|    setosa|[4.4,3.0,1.3,0.2]|       2.0|[-1.4854443073272...|[0.00769940251484...|       2.0|\n    41|        5.0|       3.5|        1.3|       0.3|    setosa|[5.0,3.5,1.3,0.3]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n    48|        4.6|       3.2|        1.4|       0.2|    setosa|[4.6,3.2,1.4,0.2]|       2.0|[-1.4854443073272...|[0.00770440697669...|       2.0|\n    56|        5.7|       2.8|        4.5|       1.3|versicolor|[5.7,2.8,4.5,1.3]|       0.0|[3.24288702011108...|[0.99279528856277...|       0.0|\n    62|        5.9|       3.0|        4.2|       1.5|versicolor|[5.9,3.0,4.2,1.5]|       0.0|[3.24288702011108...|[0.99249744415283...|       0.0|\n    78|        6.7|       3.0|        5.0|       1.7|versicolor|[6.7,3.0,5.0,1.7]|       0.0|[-2.1966855525970...|[0.00137436285149...|       1.0|\n    81|        5.5|       2.4|        3.8|       1.1|versicolor|[5.5,2.4,3.8,1.1]|       0.0|[3.11532020568847...|[0.98833745718002...|       0.0|\n    86|        6.0|       3.4|        4.5|       1.6|versicolor|[6.0,3.4,4.5,1.6]|       0.0|[3.24288702011108...|[0.99256646633148...|       0.0|\n    96|        5.7|       3.0|        4.2|       1.2|versicolor|[5.7,3.0,4.2,1.2]|       0.0|[3.24288702011108...|[0.99289292097091...|       0.0|\n+------+-----------+----------+-----------+----------+----------+-----------------+----------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\nThe model accuracy is : 0.9648572842765221\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.ml.tuning._\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.types._\nimport org.mlflow.tracking.ActiveRun\nimport org.mlflow.tracking.MlflowContext\nimport org.mlflow.tracking.MlflowClient\nimport java.io.{File, PrintWriter}\nimport ml.dmlc.xgboost4j.scala.spark.{XGBoostClassifier, XGBoostClassificationModel}\nuser: String = stephen.offer@databricks.com\nrawInput: org.apache.spark.sql.DataFrame = [rowNum: int, SepalLength: double ... 4 more fields]\ntraining: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [rowNum: int, SepalLength: double ... 4 more fields]\ntest: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [rowNum: int, SepalLength: double ... 4 more fields]\nassembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_96bbae204da6, handleInvalid=error, numInputCols=4\nlabelIndexer: org.apache.spark.ml.feature.StringIndexerModel = StringIndexerModel: uid=strIdx_8df10df736fa, handleInvalid=error\nbooster: ml.dmlc.xgboost4j.scala.spark.XGBoostClassifier = xgbc_d8d72f78e3f7\npipeline: org.apache.spark.ml.Pipeline = pipeline_b38c61b1669c\nmlflowContext: org.mlflow.tracking.MlflowContext = org.mlflow.tracking.MlflowContext@7c2b7f58\nexperimentName: String = /Users/stephen.offer@databricks.com/xgboost4j-spark-quickstart\nclient: org.mlflow.tracking.MlflowClient = org.mlflow.tracking.MlflowClient@24feb978\nexperimentOpt: java.util.Optional[org.mlflow.api.proto.Service.Experiment] =\nOptional[experiment_id: &quot;7845269&quot;\nname: &quot;/Users/stephen.offer@databricks.com/xgboost4j-spark-quickstart&quot;\nartifact_location: &quot;dbfs:/databricks/mlflow/7845269&quot;\nlifecycle_stage: &quot;active&quot;\nlast_update_time: 1597179788753\ncreation_time: 1597179788753\n]\nrun: org.mlflow.tracking.ActiveRun = org.mlflow.tracking.ActiveRun@68d65259\nmodel: org.apache.spark.ml.PipelineModel = pipeline_b38c61b1669c\nprediction: org.apache.spark.sql.DataFrame = [rowNum: int, SepalLength: double ... 9 more fields]\nevaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = MulticlassClassificationEvaluator: uid=mcEval_729d66c26560, metricName=f1, metricLabel=0.0, beta=1.0, eps=1.0E-15\naccuracy: Double = 0.9648572842765221\nscratchDir: String = dbfs:/tmp/stephen.offer@databricks.com/xgboost-model\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### XGBoost4J-Spark PySpark Example\n\nDespite not having an official Python API, a PySpark wrapper can be used to train a XGBoost4J-Spark model. In this example, we are using an unofficial wrapper which can be found here (https://github.com/sllynn/spark-xgboost)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ff5866f-eb3c-460e-9248-1ff2d829fc6d"}}},{"cell_type":"code","source":["%sh\ngit clone https://github.com/sllynn/spark-xgboost.git;\ncd spark-xgboost;\npip install -e .;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"79f7ca2a-0f69-4680-9410-1a7a985ee317"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">fatal: destination path &#39;spark-xgboost&#39; already exists and is not an empty directory.\nObtaining file:///databricks/driver/spark-xgboost\nInstalling collected packages: spark-xgboost\n  Attempting uninstall: spark-xgboost\n    Found existing installation: spark-xgboost 0.90\n    Uninstalling spark-xgboost-0.90:\n      Successfully uninstalled spark-xgboost-0.90\n  Running setup.py develop for spark-xgboost\nSuccessfully installed spark-xgboost\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">fatal: destination path &#39;spark-xgboost&#39; already exists and is not an empty directory.\nObtaining file:///databricks/driver/spark-xgboost\nInstalling collected packages: spark-xgboost\n  Attempting uninstall: spark-xgboost\n    Found existing installation: spark-xgboost 0.90\n    Uninstalling spark-xgboost-0.90:\n      Successfully uninstalled spark-xgboost-0.90\n  Running setup.py develop for spark-xgboost\nSuccessfully installed spark-xgboost\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\n# Restart Python if the installed library raises an ImportError\ndbutils.library.restartPython()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"906e2d86-750b-4ecd-8f2c-68936c125ad8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%python\n# Code taken from https://github.com/sllynn/spark-xgboost/blob/master/examples/spark-xgboost_adultdataset.ipynb\nfrom sparkxgb import XGBoostClassifier, XGBoostRegressor\nfrom pprint import PrettyPrinter\n\nfrom pyspark.sql.types import StringType\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\npp = PrettyPrinter()\n\ncol_names = [\n  \"age\", \"workclass\", \"fnlwgt\",\n  \"education\", \"education-num\",\n  \"marital-status\", \"occupation\",\n  \"relationship\", \"race\", \"sex\",\n  \"capital-gain\", \"capital-loss\",\n  \"hours-per-week\", \"native-country\",\n  \"label\"\n]\n\ntrain_sdf, test_sdf = (\n  spark.read.csv(\n    path=\"/databricks-datasets/adult/adult.data\",\n    inferSchema=True  \n  )\n  .toDF(*col_names)\n  .repartition(200)\n  .randomSplit([0.8, 0.2])\n)\n\nstring_columns = [fld.name for fld in train_sdf.schema.fields if isinstance(fld.dataType, StringType)]\nstring_col_replacements = [fld + \"_ix\" for fld in string_columns]\nstring_column_map=list(zip(string_columns, string_col_replacements))\ntarget = string_col_replacements[-1]\npredictors = [fld.name for fld in train_sdf.schema.fields if not isinstance(fld.dataType, StringType)] + string_col_replacements[:-1]\npp.pprint(\n  dict(\n    string_column_map=string_column_map,\n    target_variable=target,\n    predictor_variables=predictors\n  )\n)\n\nsi = [StringIndexer(inputCol=fld[0], outputCol=fld[1]) for fld in string_column_map]\nva = VectorAssembler(inputCols=predictors, outputCol=\"features\")\npipeline = Pipeline(stages=[*si, va])\nfitted_pipeline = pipeline.fit(train_sdf.union(test_sdf))\n\ntrain_sdf_prepared = fitted_pipeline.transform(train_sdf)\ntrain_sdf_prepared.cache()\ntrain_sdf_prepared.count()\n\ntest_sdf_prepared = fitted_pipeline.transform(test_sdf)\ntest_sdf_prepared.cache()\ntest_sdf_prepared.count()\n\nxgbParams = dict(\n  eta=0.1,\n  maxDepth=2,\n  missing=0.0,\n  objective=\"binary:logistic\",\n  numRound=5,\n  numWorkers=2\n)\n\nxgb = (\n  XGBoostClassifier(**xgbParams)\n  .setFeaturesCol(\"features\")\n  .setLabelCol(\"label_ix\")\n)\n\nbce = BinaryClassificationEvaluator(\n  rawPredictionCol=\"rawPrediction\",\n  labelCol=\"label_ix\"\n)\n\nparam_grid = (\n  ParamGridBuilder()\n  .addGrid(xgb.eta, [1e-1, 1e-2, 1e-3])\n  .addGrid(xgb.maxDepth, [2, 4, 8])\n  .build()\n)\n\ncv = CrossValidator(\n  estimator=xgb,\n  estimatorParamMaps=param_grid,\n  evaluator=bce,#mce,\n  numFolds=5\n)\n\nimport mlflow\nimport mlflow.spark\n\nspark_model_name = \"best_model_spark\"\n\nwith mlflow.start_run():\n  model = cv.fit(train_sdf_prepared)\n  best_params = dict(\n    eta_best=model.bestModel.getEta(),\n    maxDepth_best=model.bestModel.getMaxDepth()\n  )\n  mlflow.log_params(best_params)\n  \n  mlflow.spark.log_model(fitted_pipeline, \"featuriser\")\n  mlflow.spark.log_model(model, spark_model_name)\n\n  metrics = dict(\n    roc_test=bce.evaluate(model.transform(test_sdf_prepared))\n  )\n  mlflow.log_metrics(metrics)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"584fb1ec-640f-49af-8086-03badc99e939"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"train_sdf","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"age","nullable":true,"type":"integer"},{"metadata":{},"name":"workclass","nullable":true,"type":"string"},{"metadata":{},"name":"fnlwgt","nullable":true,"type":"double"},{"metadata":{},"name":"education","nullable":true,"type":"string"},{"metadata":{},"name":"education-num","nullable":true,"type":"double"},{"metadata":{},"name":"marital-status","nullable":true,"type":"string"},{"metadata":{},"name":"occupation","nullable":true,"type":"string"},{"metadata":{},"name":"relationship","nullable":true,"type":"string"},{"metadata":{},"name":"race","nullable":true,"type":"string"},{"metadata":{},"name":"sex","nullable":true,"type":"string"},{"metadata":{},"name":"capital-gain","nullable":true,"type":"double"},{"metadata":{},"name":"capital-loss","nullable":true,"type":"double"},{"metadata":{},"name":"hours-per-week","nullable":true,"type":"double"},{"metadata":{},"name":"native-country","nullable":true,"type":"string"},{"metadata":{},"name":"label","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"test_sdf","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"age","nullable":true,"type":"integer"},{"metadata":{},"name":"workclass","nullable":true,"type":"string"},{"metadata":{},"name":"fnlwgt","nullable":true,"type":"double"},{"metadata":{},"name":"education","nullable":true,"type":"string"},{"metadata":{},"name":"education-num","nullable":true,"type":"double"},{"metadata":{},"name":"marital-status","nullable":true,"type":"string"},{"metadata":{},"name":"occupation","nullable":true,"type":"string"},{"metadata":{},"name":"relationship","nullable":true,"type":"string"},{"metadata":{},"name":"race","nullable":true,"type":"string"},{"metadata":{},"name":"sex","nullable":true,"type":"string"},{"metadata":{},"name":"capital-gain","nullable":true,"type":"double"},{"metadata":{},"name":"capital-loss","nullable":true,"type":"double"},{"metadata":{},"name":"hours-per-week","nullable":true,"type":"double"},{"metadata":{},"name":"native-country","nullable":true,"type":"string"},{"metadata":{},"name":"label","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"train_sdf_prepared","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"age","nullable":true,"type":"integer"},{"metadata":{},"name":"workclass","nullable":true,"type":"string"},{"metadata":{},"name":"fnlwgt","nullable":true,"type":"double"},{"metadata":{},"name":"education","nullable":true,"type":"string"},{"metadata":{},"name":"education-num","nullable":true,"type":"double"},{"metadata":{},"name":"marital-status","nullable":true,"type":"string"},{"metadata":{},"name":"occupation","nullable":true,"type":"string"},{"metadata":{},"name":"relationship","nullable":true,"type":"string"},{"metadata":{},"name":"race","nullable":true,"type":"string"},{"metadata":{},"name":"sex","nullable":true,"type":"string"},{"metadata":{},"name":"capital-gain","nullable":true,"type":"double"},{"metadata":{},"name":"capital-loss","nullable":true,"type":"double"},{"metadata":{},"name":"hours-per-week","nullable":true,"type":"double"},{"metadata":{},"name":"native-country","nullable":true,"type":"string"},{"metadata":{},"name":"label","nullable":true,"type":"string"},{"metadata":{"ml_attr":{"name":"workclass_ix","type":"nominal","vals":[" Private"," Self-emp-not-inc"," Local-gov"," ?"," State-gov"," Self-emp-inc"," Federal-gov"," Without-pay"," Never-worked"]}},"name":"workclass_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"education_ix","type":"nominal","vals":[" HS-grad"," Some-college"," Bachelors"," Masters"," Assoc-voc"," 11th"," Assoc-acdm"," 10th"," 7th-8th"," Prof-school"," 9th"," 12th"," Doctorate"," 5th-6th"," 1st-4th"," Preschool"]}},"name":"education_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"marital-status_ix","type":"nominal","vals":[" Married-civ-spouse"," Never-married"," Divorced"," Separated"," Widowed"," Married-spouse-absent"," Married-AF-spouse"]}},"name":"marital-status_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"occupation_ix","type":"nominal","vals":[" Prof-specialty"," Craft-repair"," Exec-managerial"," Adm-clerical"," Sales"," Other-service"," Machine-op-inspct"," ?"," Transport-moving"," Handlers-cleaners"," Farming-fishing"," Tech-support"," Protective-serv"," Priv-house-serv"," Armed-Forces"]}},"name":"occupation_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"relationship_ix","type":"nominal","vals":[" Husband"," Not-in-family"," Own-child"," Unmarried"," Wife"," Other-relative"]}},"name":"relationship_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"race_ix","type":"nominal","vals":[" White"," Black"," Asian-Pac-Islander"," Amer-Indian-Eskimo"," Other"]}},"name":"race_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"sex_ix","type":"nominal","vals":[" Male"," Female"]}},"name":"sex_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"native-country_ix","type":"nominal","vals":[" United-States"," Mexico"," ?"," Philippines"," Germany"," Canada"," Puerto-Rico"," El-Salvador"," India"," Cuba"," England"," Jamaica"," South"," China"," Italy"," Dominican-Republic"," Vietnam"," Guatemala"," Japan"," Poland"," Columbia"," Taiwan"," Haiti"," Iran"," Portugal"," Nicaragua"," Peru"," France"," Greece"," Ecuador"," Ireland"," Hong"," Cambodia"," Trinadad&Tobago"," Laos"," Thailand"," Yugoslavia"," Outlying-US(Guam-USVI-etc)"," Honduras"," Hungary"," Scotland"," Holand-Netherlands"]}},"name":"native-country_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"label_ix","type":"nominal","vals":[" <=50K"," >50K"]}},"name":"label_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"attrs":{"nominal":[{"idx":6,"name":"workclass_ix","vals":[" Private"," Self-emp-not-inc"," Local-gov"," ?"," State-gov"," Self-emp-inc"," Federal-gov"," Without-pay"," Never-worked"]},{"idx":7,"name":"education_ix","vals":[" HS-grad"," Some-college"," Bachelors"," Masters"," Assoc-voc"," 11th"," Assoc-acdm"," 10th"," 7th-8th"," Prof-school"," 9th"," 12th"," Doctorate"," 5th-6th"," 1st-4th"," Preschool"]},{"idx":8,"name":"marital-status_ix","vals":[" Married-civ-spouse"," Never-married"," Divorced"," Separated"," Widowed"," Married-spouse-absent"," Married-AF-spouse"]},{"idx":9,"name":"occupation_ix","vals":[" Prof-specialty"," Craft-repair"," Exec-managerial"," Adm-clerical"," Sales"," Other-service"," Machine-op-inspct"," ?"," Transport-moving"," Handlers-cleaners"," Farming-fishing"," Tech-support"," Protective-serv"," Priv-house-serv"," Armed-Forces"]},{"idx":10,"name":"relationship_ix","vals":[" Husband"," Not-in-family"," Own-child"," Unmarried"," Wife"," Other-relative"]},{"idx":11,"name":"race_ix","vals":[" White"," Black"," Asian-Pac-Islander"," Amer-Indian-Eskimo"," Other"]},{"idx":12,"name":"sex_ix","vals":[" Male"," Female"]},{"idx":13,"name":"native-country_ix","vals":[" United-States"," Mexico"," ?"," Philippines"," Germany"," Canada"," Puerto-Rico"," El-Salvador"," India"," Cuba"," England"," Jamaica"," South"," China"," Italy"," Dominican-Republic"," Vietnam"," Guatemala"," Japan"," Poland"," Columbia"," Taiwan"," Haiti"," Iran"," Portugal"," Nicaragua"," Peru"," France"," Greece"," Ecuador"," Ireland"," Hong"," Cambodia"," Trinadad&Tobago"," Laos"," Thailand"," Yugoslavia"," Outlying-US(Guam-USVI-etc)"," Honduras"," Hungary"," Scotland"," Holand-Netherlands"]}],"numeric":[{"idx":0,"name":"age"},{"idx":1,"name":"fnlwgt"},{"idx":2,"name":"education-num"},{"idx":3,"name":"capital-gain"},{"idx":4,"name":"capital-loss"},{"idx":5,"name":"hours-per-week"}]},"num_attrs":14}},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null},{"name":"test_sdf_prepared","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"age","nullable":true,"type":"integer"},{"metadata":{},"name":"workclass","nullable":true,"type":"string"},{"metadata":{},"name":"fnlwgt","nullable":true,"type":"double"},{"metadata":{},"name":"education","nullable":true,"type":"string"},{"metadata":{},"name":"education-num","nullable":true,"type":"double"},{"metadata":{},"name":"marital-status","nullable":true,"type":"string"},{"metadata":{},"name":"occupation","nullable":true,"type":"string"},{"metadata":{},"name":"relationship","nullable":true,"type":"string"},{"metadata":{},"name":"race","nullable":true,"type":"string"},{"metadata":{},"name":"sex","nullable":true,"type":"string"},{"metadata":{},"name":"capital-gain","nullable":true,"type":"double"},{"metadata":{},"name":"capital-loss","nullable":true,"type":"double"},{"metadata":{},"name":"hours-per-week","nullable":true,"type":"double"},{"metadata":{},"name":"native-country","nullable":true,"type":"string"},{"metadata":{},"name":"label","nullable":true,"type":"string"},{"metadata":{"ml_attr":{"name":"workclass_ix","type":"nominal","vals":[" Private"," Self-emp-not-inc"," Local-gov"," ?"," State-gov"," Self-emp-inc"," Federal-gov"," Without-pay"," Never-worked"]}},"name":"workclass_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"education_ix","type":"nominal","vals":[" HS-grad"," Some-college"," Bachelors"," Masters"," Assoc-voc"," 11th"," Assoc-acdm"," 10th"," 7th-8th"," Prof-school"," 9th"," 12th"," Doctorate"," 5th-6th"," 1st-4th"," Preschool"]}},"name":"education_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"marital-status_ix","type":"nominal","vals":[" Married-civ-spouse"," Never-married"," Divorced"," Separated"," Widowed"," Married-spouse-absent"," Married-AF-spouse"]}},"name":"marital-status_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"occupation_ix","type":"nominal","vals":[" Prof-specialty"," Craft-repair"," Exec-managerial"," Adm-clerical"," Sales"," Other-service"," Machine-op-inspct"," ?"," Transport-moving"," Handlers-cleaners"," Farming-fishing"," Tech-support"," Protective-serv"," Priv-house-serv"," Armed-Forces"]}},"name":"occupation_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"relationship_ix","type":"nominal","vals":[" Husband"," Not-in-family"," Own-child"," Unmarried"," Wife"," Other-relative"]}},"name":"relationship_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"race_ix","type":"nominal","vals":[" White"," Black"," Asian-Pac-Islander"," Amer-Indian-Eskimo"," Other"]}},"name":"race_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"sex_ix","type":"nominal","vals":[" Male"," Female"]}},"name":"sex_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"native-country_ix","type":"nominal","vals":[" United-States"," Mexico"," ?"," Philippines"," Germany"," Canada"," Puerto-Rico"," El-Salvador"," India"," Cuba"," England"," Jamaica"," South"," China"," Italy"," Dominican-Republic"," Vietnam"," Guatemala"," Japan"," Poland"," Columbia"," Taiwan"," Haiti"," Iran"," Portugal"," Nicaragua"," Peru"," France"," Greece"," Ecuador"," Ireland"," Hong"," Cambodia"," Trinadad&Tobago"," Laos"," Thailand"," Yugoslavia"," Outlying-US(Guam-USVI-etc)"," Honduras"," Hungary"," Scotland"," Holand-Netherlands"]}},"name":"native-country_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"name":"label_ix","type":"nominal","vals":[" <=50K"," >50K"]}},"name":"label_ix","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"attrs":{"nominal":[{"idx":6,"name":"workclass_ix","vals":[" Private"," Self-emp-not-inc"," Local-gov"," ?"," State-gov"," Self-emp-inc"," Federal-gov"," Without-pay"," Never-worked"]},{"idx":7,"name":"education_ix","vals":[" HS-grad"," Some-college"," Bachelors"," Masters"," Assoc-voc"," 11th"," Assoc-acdm"," 10th"," 7th-8th"," Prof-school"," 9th"," 12th"," Doctorate"," 5th-6th"," 1st-4th"," Preschool"]},{"idx":8,"name":"marital-status_ix","vals":[" Married-civ-spouse"," Never-married"," Divorced"," Separated"," Widowed"," Married-spouse-absent"," Married-AF-spouse"]},{"idx":9,"name":"occupation_ix","vals":[" Prof-specialty"," Craft-repair"," Exec-managerial"," Adm-clerical"," Sales"," Other-service"," Machine-op-inspct"," ?"," Transport-moving"," Handlers-cleaners"," Farming-fishing"," Tech-support"," Protective-serv"," Priv-house-serv"," Armed-Forces"]},{"idx":10,"name":"relationship_ix","vals":[" Husband"," Not-in-family"," Own-child"," Unmarried"," Wife"," Other-relative"]},{"idx":11,"name":"race_ix","vals":[" White"," Black"," Asian-Pac-Islander"," Amer-Indian-Eskimo"," Other"]},{"idx":12,"name":"sex_ix","vals":[" Male"," Female"]},{"idx":13,"name":"native-country_ix","vals":[" United-States"," Mexico"," ?"," Philippines"," Germany"," Canada"," Puerto-Rico"," El-Salvador"," India"," Cuba"," England"," Jamaica"," South"," China"," Italy"," Dominican-Republic"," Vietnam"," Guatemala"," Japan"," Poland"," Columbia"," Taiwan"," Haiti"," Iran"," Portugal"," Nicaragua"," Peru"," France"," Greece"," Ecuador"," Ireland"," Hong"," Cambodia"," Trinadad&Tobago"," Laos"," Thailand"," Yugoslavia"," Outlying-US(Guam-USVI-etc)"," Honduras"," Hungary"," Scotland"," Holand-Netherlands"]}],"numeric":[{"idx":0,"name":"age"},{"idx":1,"name":"fnlwgt"},{"idx":2,"name":"education-num"},{"idx":3,"name":"capital-gain"},{"idx":4,"name":"capital-loss"},{"idx":5,"name":"hours-per-week"}]},"num_attrs":14}},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">{&#39;predictor_variables&#39;: [&#39;age&#39;,\n                         &#39;fnlwgt&#39;,\n                         &#39;education-num&#39;,\n                         &#39;capital-gain&#39;,\n                         &#39;capital-loss&#39;,\n                         &#39;hours-per-week&#39;,\n                         &#39;workclass_ix&#39;,\n                         &#39;education_ix&#39;,\n                         &#39;marital-status_ix&#39;,\n                         &#39;occupation_ix&#39;,\n                         &#39;relationship_ix&#39;,\n                         &#39;race_ix&#39;,\n                         &#39;sex_ix&#39;,\n                         &#39;native-country_ix&#39;],\n &#39;string_column_map&#39;: [(&#39;workclass&#39;, &#39;workclass_ix&#39;),\n                       (&#39;education&#39;, &#39;education_ix&#39;),\n                       (&#39;marital-status&#39;, &#39;marital-status_ix&#39;),\n                       (&#39;occupation&#39;, &#39;occupation_ix&#39;),\n                       (&#39;relationship&#39;, &#39;relationship_ix&#39;),\n                       (&#39;race&#39;, &#39;race_ix&#39;),\n                       (&#39;sex&#39;, &#39;sex_ix&#39;),\n                       (&#39;native-country&#39;, &#39;native-country_ix&#39;),\n                       (&#39;label&#39;, &#39;label_ix&#39;)],\n &#39;target_variable&#39;: &#39;label_ix&#39;}\nMLlib will automatically track trials in MLflow. After your tuning fit() call has completed, view the MLflow UI to see logged runs.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{&#39;predictor_variables&#39;: [&#39;age&#39;,\n                         &#39;fnlwgt&#39;,\n                         &#39;education-num&#39;,\n                         &#39;capital-gain&#39;,\n                         &#39;capital-loss&#39;,\n                         &#39;hours-per-week&#39;,\n                         &#39;workclass_ix&#39;,\n                         &#39;education_ix&#39;,\n                         &#39;marital-status_ix&#39;,\n                         &#39;occupation_ix&#39;,\n                         &#39;relationship_ix&#39;,\n                         &#39;race_ix&#39;,\n                         &#39;sex_ix&#39;,\n                         &#39;native-country_ix&#39;],\n &#39;string_column_map&#39;: [(&#39;workclass&#39;, &#39;workclass_ix&#39;),\n                       (&#39;education&#39;, &#39;education_ix&#39;),\n                       (&#39;marital-status&#39;, &#39;marital-status_ix&#39;),\n                       (&#39;occupation&#39;, &#39;occupation_ix&#39;),\n                       (&#39;relationship&#39;, &#39;relationship_ix&#39;),\n                       (&#39;race&#39;, &#39;race_ix&#39;),\n                       (&#39;sex&#39;, &#39;sex_ix&#39;),\n                       (&#39;native-country&#39;, &#39;native-country_ix&#39;),\n                       (&#39;label&#39;, &#39;label_ix&#39;)],\n &#39;target_variable&#39;: &#39;label_ix&#39;}\nMLlib will automatically track trials in MLflow. After your tuning fit() call has completed, view the MLflow UI to see logged runs.\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"xgboost4j-spark-example","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3770691405153605}},"nbformat":4,"nbformat_minor":0}
